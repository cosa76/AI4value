import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.cloud import bigquery
import plotly.express as px

# D√©finition de la cl√© d'authentification Google Cloud
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "Load_file_in_bigquery/dbt_sa_bigquery.json"


def rename_duplicate_columns(df):
    """
    Renomme les colonnes en doublon dans un DataFrame.
    Exemple: si deux colonnes 'col1', alors deviennent 'col1' et 'col1_1'.
    """
    cols = df.columns.tolist()
    new_cols = []
    seen = {}

    for col in cols:
        if col in seen:
            seen[col] += 1
            new_cols.append(f"{col}_{seen[col]}")
        else:
            seen[col] = 0
            new_cols.append(col)
    df.columns = new_cols
    return df


def authenticate_bigquery():
    """
    Authentification aupr√®s de BigQuery.
    """
    try:
        client = bigquery.Client()
        print("Authentification r√©ussie √† BigQuery!")
        return client
    except Exception as e:
        print(f"Erreur d'authentification: {e}")
        return None


def list_views(client, project_id, dataset_id):
    """
    Liste toutes les vues disponibles dans le dataset sp√©cifi√©.
    """
    dataset_ref = client.dataset(dataset_id, project=project_id)
    try:
        tables = list(client.list_tables(dataset_ref))
        views = [table.table_id for table in tables if table.table_type == 'VIEW']
        if not views:
            print(f"Aucune vue trouv√©e dans le dataset {dataset_id}")
        return views
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des vues: {e}")
        return []


def get_view_query(client, project_id, dataset_id, view_id):
    """
    R√©cup√®re la requ√™te SQL source d'une vue existante.
    """
    view_ref = client.dataset(dataset_id, project=project_id).table(view_id)
    try:
        view = client.get_table(view_ref)
        return view.view_query
    except Exception as e:
        print(f"Impossible de r√©cup√©rer la requ√™te de la vue {view_id}: {e}")
        return None


def generate_clean_sql_from_query(sql_query, df):
    """
    G√©n√®re une requ√™te SQL propre avec des colonnes renomm√©es pour √©viter les doublons.
    """
    if not sql_query or not df.columns.tolist():
        return sql_query

    original_columns = df.columns.tolist()
    cleaned_columns = []
    seen = {}

    for col in original_columns:
        if col in seen:
            seen[col] += 1
            cleaned_columns.append(f"`{col}` AS `{col}_{seen[col]}`")
        else:
            seen[col] = 0
            cleaned_columns.append(f"`{col}`")

    select_clause = ", ".join(cleaned_columns)
    return f"SELECT {select_clause} FROM ({sql_query})"


def recreate_view(client, project_id, dataset_id, view_id, clean_sql):
    """
    Recr√©e une vue dans BigQuery avec une requ√™te SQL nettoy√©e (sans doublons).
    """
    view_ref = client.dataset(dataset_id, project=project_id).table(view_id)
    try:
        view = bigquery.Table(view_ref)
        view.view_query = clean_sql
        view = client.update_table(view, ["view_query"])
        print(f"‚úÖ Vue '{view_id}' mise √† jour sans doublons.")
    except Exception as e:
        print(f"‚ùå Erreur lors de la mise √† jour de la vue '{view_id}': {e}")


def get_view_data(client, project_id, dataset_id, view_id, limit=1000):
    """
    R√©cup√®re les donn√©es d'une vue sp√©cifique et corrige les doublons de colonnes.
    """
    query = f"""
    SELECT * 
    FROM `{project_id}.{dataset_id}.{view_id}`
    LIMIT {limit}
    """
    try:
        df = client.query(query).to_dataframe()
        df = rename_duplicate_columns(df)
        print(f"‚úÖ Donn√©es r√©cup√©r√©es avec succ√®s: {len(df)} lignes")
        return df
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es de la vue {view_id}: {e}")
        return None


def analyze_dataframe(df, view_name):
    """
    Analyse exploratoire des donn√©es et cr√©ation de visualisations (simplifi√©e ici).
    """
    if df is None or df.empty:
        print("‚ö†Ô∏è Aucune donn√©e √† analyser")
        return

    print(f"\n--- Analyse de la vue: {view_name} ---")
    print(f"Dimensions: {df.shape[0]} lignes x {df.shape[1]} colonnes")
    print("\nTypes de donn√©es:")
    print(df.dtypes)

    viz_folder = f"visualisations_{view_name}"
    os.makedirs(viz_folder, exist_ok=True)

    # Histogramme simple
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
    if len(numeric_cols) > 0:
        col = numeric_cols[0]
        try:
            plt.figure(figsize=(10, 6))
            sns.histplot(df[col].dropna(), kde=True)
            plt.title(f'Distribution de {col}')
            plt.tight_layout()
            plt.savefig(f"{viz_folder}/hist_{col}.png")
            plt.close()
            print(f"üìä Histogramme g√©n√©r√© pour {col}")
        except Exception as e:
            print(f"‚ùå √âchec de g√©n√©ration de l'histogramme pour {col}: {e}")

    print(f"\nVisualisations sauvegard√©es dans le dossier '{viz_folder}'")


def main():
    # Configuration
    project_id = "sandbox-jndong"
    dataset_id = "DataOriginal_matching"

    # Authentification
    client = authenticate_bigquery()
    if not client:
        return

    # R√©cup√©ration des vues
    views = list_views(client, project_id, dataset_id)
    if not views:
        return

    print("\nVues disponibles:")
    for i, view in enumerate(views, 1):
        print(f"{i}. {view}")

    # S√©lection de la vue √† traiter
    try:
        choice = int(input("\nEntrez le num√©ro de la vue √† analyser (0 pour toutes): "))
        if choice == 0:
            selected_views = views
        elif 1 <= choice <= len(views):
            selected_views = [views[choice - 1]]
        else:
            print("‚ùå Choix invalide")
            return
    except ValueError:
        print("‚ùå Veuillez entrer un nombre valide")
        return

    # Traitement des vues s√©lectionn√©es
    all_viz_folders = []
    for view in selected_views:
        print(f"\nüîç Traitement de la vue: {view}")

        # R√©cup√©ration des donn√©es
        df = get_view_data(client, project_id, dataset_id, view)
        if df is None:
            continue

        # Analyse exploratoire
        viz_folder = analyze_dataframe(df, view)
        if viz_folder:
            all_viz_folders.append(viz_folder)

        # R√©cup√©ration de la requ√™te SQL originale
        sql_query = get_view_query(client, project_id, dataset_id, view)
        if not sql_query:
            continue

        # Nettoyage de la requ√™te SQL
        clean_sql = generate_clean_sql_from_query(sql_query, df)
        if not clean_sql:
            print(f"‚ùå Impossible de g√©n√©rer une requ√™te SQL propre pour {view}")
            continue

        # Mise √† jour de la vue dans BigQuery
        recreate_view(client, project_id, dataset_id, view, clean_sql)

    if all_viz_folders:
        print("\nüìä R√©sum√© des analyses:")
        for folder in all_viz_folders:
            print(f"- Visualisations g√©n√©r√©es dans : {folder}")


if __name__ == "__main__":
    main()